\begin{thebibliography}{52}
\providecommand{\biband}{和}
\providecommand{\bibetal}{等}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{#1}
\expandafter\ifx\csname urlstyle\endcsname\relax\else
  \urlstyle{same}\fi
\expandafter\ifx\csname href\endcsname\relax
  \DeclareUrlCommand\doi{\urlstyle{rm}}
  \def\eprint#1#2{#2}
\else
  \def\doi#1{\href{https://doi.org/#1}{\nolinkurl{#1}}}
  \let\eprint\href
\fi

\bibitem[Turing(2006)]{turing2006imitation}
Turing A~M.
\newblock The imitation game\allowbreak[Z].
\newblock 2006.

\bibitem[Li {\bibetal}(2022)Li, Quan, Wang, Xiao, Jiang, Hu, and
  Du]{DBLP:conf/seke/LiQWXJHD22}
Li L, Quan Z, Wang Z, et~al.
\newblock {RIRCNN:} {A} fault diagnosis method for aviation turboprop
  engine\allowbreak[C]//\allowbreak
Peng R, Pantoja C~E, Kamthan P.
\newblock The 34th International Conference on Software Engineering and
  Knowledge Engineering, {SEKE} 2022, {KSIR} Virtual Conference Center, USA,
  July 1 - July 10, 2022.
\newblock {KSI} Research Inc., 2022: 220-224.
\newblock \url{https://doi.org/10.18293/SEKE2022-112}.

\bibitem[Sato(2020)]{DBLP:conf/ispdc/Sato20}
Sato M.
\newblock The supercomputer "fugaku" and arm-sve enabled {A64FX} processor for
  energy-efficiency and sustained application
  performance\allowbreak[C]//\allowbreak
19th International Symposium on Parallel and Distributed Computing, {ISPDC}
  2020, Warsaw, Poland, July 5-8, 2020.
\newblock {IEEE}, 2020: 1-5.
\newblock \url{https://doi.org/10.1109/ISPDC51135.2020.00009}.

\bibitem[Sato {\bibetal}(2020)Sato, Ishikawa, Tomita, Kodama, Odajima, Tsuji,
  Yashiro, Aoki, Shida, Miyoshi, et~al.]{sato2020co}
Sato M, Ishikawa Y, Tomita H, et~al.
\newblock Co-design for a64fx manycore processor and”
  fugaku”\allowbreak[C]//\allowbreak
SC20: International Conference for High Performance Computing, Networking,
  Storage and Analysis.
\newblock IEEE, 2020: 1-15.

\bibitem[van~de Geijn {\bibetal}(2011)van~de Geijn and
  Goto]{DBLP:reference/parallel/GeijnG11}
van~de Geijn R~A, Goto K.
\newblock {BLAS} (basic linear algebra subprograms)\allowbreak[M]//\allowbreak
Padua D~A.
\newblock Encyclopedia of Parallel Computing.
\newblock Springer, 2011: 157-164.
\newblock \url{https://doi.org/10.1007/978-0-387-09766-4\_84}.

\bibitem[Jia {\bibetal}(2014)Jia, Shelhamer, Donahue, Karayev, Long, Girshick,
  Guadarrama, and Darrell]{jia2014caffe}
Jia Y, Shelhamer E, Donahue J, et~al.
\newblock Caffe: Convolutional architecture for fast feature
  embedding\allowbreak[C]//\allowbreak
Proceedings of the 22nd ACM international conference on Multimedia.
\newblock 2014: 675-678.

\bibitem[Abadi {\bibetal}(2016)Abadi, Barham, Chen, Chen, Davis, Dean, Devin,
  Ghemawat, Irving, Isard, et~al.]{abadi2016tensorflow}
Abadi M, Barham P, Chen J, et~al.
\newblock Tensorflow: a system for large-scale machine
  learning.\allowbreak[C]//\allowbreak
Osdi: volume~16.
\newblock Savannah, GA, USA, 2016: 265-283.

\bibitem[Jouppi {\bibetal}(2021)Jouppi, Yoon, Ashcraft, Gottscho, Jablin,
  Kurian, Laudon, Li, Ma, Ma, Norrie, Patil, Prasad, Young, Zhou, and
  Patterson]{DBLP:conf/isca/JouppiYAGJKLLMM21}
Jouppi N~P, Yoon D~H, Ashcraft M, et~al.
\newblock Ten lessons from three generations shaped google's tpuv4i :
  Industrial product\allowbreak[C]//\allowbreak
48th {ACM/IEEE} Annual International Symposium on Computer Architecture, {ISCA}
  2021, Valencia, Spain, June 14-18, 2021.
\newblock {IEEE}, 2021: 1-14.
\newblock \url{https://doi.org/10.1109/ISCA52012.2021.00010}.

\bibitem[Paszke {\bibetal}(2019)Paszke, Gross, Massa, Lerer, Bradbury, Chanan,
  Killeen, Lin, Gimelshein, Antiga, et~al.]{paszke2019pytorch}
Paszke A, Gross S, Massa F, et~al.
\newblock Pytorch: An imperative style, high-performance deep learning
  library\allowbreak[J].
\newblock Advances in neural information processing systems, 2019, 32.

\bibitem[Bradbury {\bibetal}(2018)Bradbury, Frostig, Hawkins, Johnson, Leary,
  Maclaurin, Necula, Paszke, Vander{P}las, Wanderman-{M}ilne, and
  Zhang]{jax2018github}
Bradbury J, Frostig R, Hawkins P, et~al.
\newblock {JAX}: composable transformations of {P}ython+{N}um{P}y
  programs\allowbreak[CP].
\newblock 2018.
\newblock \url{http://github.com/google/jax}.

\bibitem[Intel(2022)]{oneAPI}
Intel.
\newblock oneapi deep neural network library (onednn)\allowbreak[M].
\newblock GitHub, 2022.
\newblock \url{https://github.com/oneapi-src/oneDNN}.

\bibitem[Stone {\bibetal}(2010)Stone, Gohara, and Shi]{stone2010opencl}
Stone J~E, Gohara D, Shi G.
\newblock Opencl: A parallel programming standard for heterogeneous computing
  systems\allowbreak[J].
\newblock Computing in science \& engineering, 2010, 12\allowbreak (3): 66.

\bibitem[Arm(2022)]{ARMACL}
Arm.
\newblock Arm-software/computelibrary\allowbreak[M].
\newblock GitHub, 2022.
\newblock \url{https://github.com/ARM-software/ComputeLibrary}.

\bibitem[Chetlur {\bibetal}(2014)Chetlur, Woolley, Vandermersch, Cohen, Tran,
  Catanzaro, and Shelhamer]{DBLP:journals/corr/ChetlurWVCTCS14}
Chetlur S, Woolley C, Vandermersch P, et~al.
\newblock cudnn: Efficient primitives for deep learning\allowbreak[J].
\newblock CoRR, 2014, abs/1410.0759.
\newblock \url{http://arxiv.org/abs/1410.0759}.

\bibitem[Jiang {\bibetal}(2020)Jiang, Wang, Chen, Wu, Wang, Zou, Yang, Cui,
  Cai, Yu, Lv, and Wu]{alibaba2020mnn}
Jiang X, Wang H, Chen Y, et~al.
\newblock Mnn: A universal and efficient inference
  engine\allowbreak[C]//\allowbreak
MLSys.
\newblock 2020.

\bibitem[Tencent(2021-04-26)]{TNN}
Tencent.
\newblock Tnn: developed by tencent youtu lab and guangying lab, a uniform deep
  learning inference framework for mobile、desktop and server.\allowbreak[J].
\newblock GitHub repository, 2021-04-26.
\newblock \url{https://github.com/Tencent/TNN}.

\bibitem[Ma {\bibetal}(2019)Ma, Yu, Wu, and Wang]{ma2019paddlepaddle}
Ma Y, Yu D, Wu T, et~al.
\newblock Paddlepaddle: An open-source deep learning platform from industrial
  practice\allowbreak[J].
\newblock Frontiers of Data and Domputing, 2019, 1\allowbreak (1): 105-115.

\bibitem[Lavin {\bibetal}(2016)Lavin and Gray]{DBLP:conf/cvpr/LavinG16}
Lavin A, Gray S.
\newblock Fast algorithms for convolutional neural
  networks\allowbreak[C]//\allowbreak
2016 {IEEE} Conference on Computer Vision and Pattern Recognition, {CVPR} 2016,
  Las Vegas, NV, USA, June 27-30, 2016.
\newblock {IEEE} Computer Society, 2016: 4013-4021.
\newblock \url{https://doi.org/10.1109/CVPR.2016.435}.

\bibitem[Mathieu {\bibetal}(2014)Mathieu, Henaff, and
  LeCun]{DBLP:journals/corr/MathieuHL13}
Mathieu M, Henaff M, LeCun Y.
\newblock Fast training of convolutional networks through
  ffts\allowbreak[C]//\allowbreak
Bengio Y, LeCun Y.
\newblock 2nd International Conference on Learning Representations, {ICLR}
  2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings.
\newblock 2014.
\newblock \url{http://arxiv.org/abs/1312.5851}.

\bibitem[Chellapilla {\bibetal}(2006)Chellapilla, Puri, and
  Simard]{chellapilla2006high}
Chellapilla K, Puri S, Simard P.
\newblock High performance convolutional neural networks for document
  processing\allowbreak[C]//\allowbreak
Tenth international workshop on frontiers in handwriting recognition.
\newblock Suvisoft, 2006.

\bibitem[Wang {\bibetal}(2021)Wang and Ma]{OptIm2col}
Wang H, Ma C.
\newblock An optimization of im2col, an important method of cnns, based on
  continuous address access\allowbreak[C]//\allowbreak
2021 IEEE International Conference on Consumer Electronics and Computer
  Engineering (ICCECE).
\newblock 2021: 314-320.
\newblock DOI: \doi{10.1109/ICCECE51280.2021.9342343}.

\bibitem[Cho {\bibetal}(2017)Cho and Brand]{cho2017mec}
Cho M, Brand D.
\newblock Mec: Memory-efficient convolution for deep neural
  network\allowbreak[A].
\newblock 2017.
\newblock arXiv: \eprint{https://arxiv.org/abs/1706.06873}{1706.06873}.

\bibitem[Dukhan(2019)]{dukhan2019indirect}
Dukhan M.
\newblock The indirect convolution algorithm\allowbreak[A].
\newblock 2019.
\newblock arXiv: \eprint{https://arxiv.org/abs/1907.02129}{1907.02129}.

\bibitem[黄春\ {\bibetal}(2022)黄春, 姜浩, 全哲, 左克, and
  刘文超何楠~&]{HeNan}
黄春, 姜浩, 全哲, 等.
\newblock
  面向深度学习的批处理矩阵乘法设计与实现\allowbreak[J].
\newblock 计算机学报, 2022, 45\allowbreak (225-239).

\bibitem[庄晨(2022)]{zhuangchen}
庄晨.
\newblock 基于CPU SIMD指令集的卷积计算优化\allowbreak[Z].
\newblock 中国科学院大学(中国科学院深圳先进技术研究院),
  2022.

\bibitem[Zebin {\bibetal}(2019)Zebin, Scully, Peek, Casson, and
  Ozanyan]{EdgeConv}
Zebin T, Scully P~J, Peek N, et~al.
\newblock Design and implementation of a convolutional neural network on an
  edge computing smartphone for human activity recognition\allowbreak[J].
\newblock IEEE Access, 2019, 7: 133509-133520.
\newblock DOI: \doi{10.1109/ACCESS.2019.2941836}.

\bibitem[Lu {\bibetal}(2022)Lu, Wang, Guo, Huang, Liu, Wang, Fang, Tang, Chen,
  Liu, et~al.]{lu2022mt}
Lu K, Wang Y, Guo Y, et~al.
\newblock Mt-3000: a heterogeneous multi-zone processor for hpc\allowbreak[J].
\newblock CCF Transactions on High Performance Computing, 2022, 4\allowbreak
  (2): 150-164.

\bibitem[Chandra {\bibetal}(2001)Chandra, Dagum, Menon, Kohr, Maydan, and
  McDonald]{chandra2001parallel}
Chandra R, Dagum L, Menon R, et~al.
\newblock Parallel programming in openmp\allowbreak[M].
\newblock Morgan kaufmann, 2001.

\bibitem[Gropp {\bibetal}(1999)Gropp, Gropp, Lusk, Skjellum, and
  Lusk]{gropp1999using}
Gropp W, Gropp W~D, Lusk E, et~al.
\newblock Using mpi: portable parallel programming with the message-passing
  interface: volume~1\allowbreak[M].
\newblock MIT press, 1999.

\bibitem[解庆春\ {\bibetal}(2011)解庆春, 张云泉, 王可, and
  许亚武李焱~&]{SIMDZH}
解庆春, 张云泉, 王可, 等.
\newblock SIMD技术与向量数学库研究\allowbreak[J].
\newblock 计算机科学, 2011, 38\allowbreak (298-301).

\bibitem[Peleg {\bibetal}(1996)Peleg and Weiser]{peleg1996mmx}
Peleg A, Weiser U.
\newblock Mmx technology extension to the intel architecture\allowbreak[J].
\newblock IEEE micro, 1996, 16\allowbreak (4): 42-50.

\bibitem[Raman {\bibetal}(2000)Raman, Pentkovski, and
  Keshava]{raman2000implementing}
Raman S~K, Pentkovski V, Keshava J.
\newblock Implementing streaming simd extensions on the pentium iii
  processor\allowbreak[J].
\newblock IEEE micro, 2000, 20\allowbreak (4): 47-57.

\bibitem[Lomont(2011)]{lomont2011introduction}
Lomont C.
\newblock Introduction to intel advanced vector extensions\allowbreak[J].
\newblock Intel white paper, 2011, 23.

\bibitem[Cornea(2015)]{cornea2015intel}
Cornea M.
\newblock Intel avx-512 instructions and their use in the implementation of
  math functions\allowbreak[J].
\newblock Intel Corporation, 2015: 1-20.

\bibitem[Reddy(2008)]{reddy2008neon}
Reddy V~G.
\newblock Neon technology introduction\allowbreak[J].
\newblock ARM Corporation, 2008, 4\allowbreak (1): 1-33.

\bibitem[Stephens {\bibetal}(2017)Stephens, Biles, Boettcher, Eapen, Eyole,
  Gabrielli, Horsnell, Magklis, Martinez, Premillieu, et~al.]{stephens2017arm}
Stephens N, Biles S, Boettcher M, et~al.
\newblock The arm scalable vector extension\allowbreak[J].
\newblock IEEE micro, 2017, 37\allowbreak (2): 26-39.

\bibitem[Wang {\bibetal}(2014)Wang, Wu, Tanase, Serrano, and
  Moreira]{wang2014simple}
Wang H, Wu P, Tanase I~G, et~al.
\newblock Simple, portable and fast simd intrinsic programming: generic simd
  library\allowbreak[C]//\allowbreak
Proceedings of the 2014 Workshop on Programming models for SIMD/Vector
  processing.
\newblock 2014: 9-16.

\bibitem[Goto {\bibetal}(2008)Goto and Geijn]{goto2008anatomy}
Goto K, Geijn R~A~v~d.
\newblock Anatomy of high-performance matrix multiplication\allowbreak[J].
\newblock ACM Transactions on Mathematical Software (TOMS), 2008, 34\allowbreak
  (3): 1-25.

\bibitem[Van~Zee {\bibetal}(2015)Van~Zee and Van De~Geijn]{van2015blis}
Van~Zee F~G, Van De~Geijn R~A.
\newblock Blis: A framework for rapidly instantiating blas
  functionality\allowbreak[J].
\newblock ACM Transactions on Mathematical Software (TOMS), 2015, 41\allowbreak
  (3): 1-33.

\bibitem[Krizhevsky {\bibetal}(2017)Krizhevsky, Sutskever, and
  Hinton]{DBLP:journals/cacm/KrizhevskySH17}
Krizhevsky A, Sutskever I, Hinton G~E.
\newblock Imagenet classification with deep convolutional neural
  networks\allowbreak[J].
\newblock Commun. {ACM}, 2017, 60\allowbreak (6): 84-90.
\newblock \url{https://doi.org/10.1145/3065386}.

\bibitem[Simonyan {\bibetal}(2015)Simonyan and
  Zisserman]{DBLP:journals/corr/SimonyanZ14a}
Simonyan K, Zisserman A.
\newblock Very deep convolutional networks for large-scale image
  recognition\allowbreak[C]//\allowbreak
Bengio Y, LeCun Y.
\newblock 3rd International Conference on Learning Representations, {ICLR}
  2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings.
\newblock 2015.
\newblock \url{http://arxiv.org/abs/1409.1556}.

\bibitem[Lecun {\bibetal}(1998)Lecun, Bottou, Bengio, and Haffner]{LeNet}
Lecun Y, Bottou L, Bengio Y, et~al.
\newblock Gradient-based learning applied to document
  recognition\allowbreak[J].
\newblock Proceedings of the IEEE, 1998, 86\allowbreak (11): 2278-2324.
\newblock DOI: \doi{10.1109/5.726791}.

\bibitem[Szegedy {\bibetal}(2014)Szegedy, Liu, Jia, Sermanet, Reed, Anguelov,
  Erhan, Vanhoucke, and Rabinovich]{szegedy2014going}
Szegedy C, Liu W, Jia Y, et~al.
\newblock Going deeper with convolutions\allowbreak[A].
\newblock 2014.
\newblock arXiv: \eprint{https://arxiv.org/abs/1409.4842}{1409.4842}.

\bibitem[He {\bibetal}(2015)He, Zhang, Ren, and Sun]{he2015deep}
He K, Zhang X, Ren S, et~al.
\newblock Deep residual learning for image recognition\allowbreak[A].
\newblock 2015.
\newblock arXiv: \eprint{https://arxiv.org/abs/1512.03385}{1512.03385}.

\bibitem[Krizhevsky {\bibetal}(2012)Krizhevsky, Sutskever, and Hinton]{LRN}
Krizhevsky A, Sutskever I, Hinton G~E.
\newblock Imagenet classification with deep convolutional neural
  networks\allowbreak[C]//\allowbreak
NIPS'12: Proceedings of the 25th International Conference on Neural Information
  Processing Systems - Volume 1.
\newblock Red Hook, NY, USA: Curran Associates Inc., 2012: 1097–1105.

\bibitem[Ioffe {\bibetal}(2015)Ioffe and Szegedy]{ioffe2015batch}
Ioffe S, Szegedy C.
\newblock Batch normalization: Accelerating deep network training by reducing
  internal covariate shift\allowbreak[A].
\newblock 2015.
\newblock arXiv: \eprint{https://arxiv.org/abs/1502.03167}{1502.03167}.

\bibitem[Rumelhart {\bibetal}(1986)Rumelhart, Hinton, and
  Williams]{rumelhart1986learning}
Rumelhart D~E, Hinton G~E, Williams R~J.
\newblock Learning representations by back-propagating errors\allowbreak[J].
\newblock nature, 1986, 323\allowbreak (6088): 533-536.

\bibitem[Malossi {\bibetal}(2015)Malossi, Ineichen, Bekas, and
  Curioni]{malossi2015fast}
Malossi A~C~I, Ineichen Y, Bekas C, et~al.
\newblock Fast exponential computation on simd architectures\allowbreak[J].
\newblock Proc. of HIPEAC-WAPCO, Amsterdam NL, 2015, 56.

\bibitem[张先轶\ {\bibetal}(2012)张先轶, 王茜, and
  张云泉]{张先轶2012openblas}
张先轶, 王茜, 张云泉.
\newblock OpenBLAS: A High Performance BLAS Library on Loongson 3A
  CPU\allowbreak[J].
\newblock Journal of Software, 2012, 22\allowbreak (zk2): 208-216.

\bibitem[Arm(2022)]{armplnet}
Arm.
\newblock Arm performance libraries\allowbreak[M].
\newblock Arm, 2022.
\newblock
  \url{https://developer.arm.com/downloads/-/arm-performance-libraries}.

\bibitem[Huang {\bibetal}(2016)Huang and Van~de Geijn]{huang2016blislab}
Huang J, Van~de Geijn R~A.
\newblock Blislab: A sandbox for optimizing gemm\allowbreak[A].
\newblock 2016.

\bibitem[Smith {\bibetal}(2014)Smith, Van De~Geijn, Smelyanskiy, Hammond, and
  Van~Zee]{smith2014anatomy}
Smith T~M, Van De~Geijn R, Smelyanskiy M, et~al.
\newblock Anatomy of high-performance many-threaded matrix
  multiplication\allowbreak[C]//\allowbreak
2014 IEEE 28th International Parallel and Distributed Processing Symposium.
\newblock IEEE, 2014: 1049-1059.

\end{thebibliography}
